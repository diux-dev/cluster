{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fp16util import *\n",
    "from resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_parser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--save-dir', type=str, default=Path.cwd(), help='Directory to save logs and models.')\n",
    "    parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\n",
    "    parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                        metavar='W', help='weight decay (default: 1e-4)')\n",
    "    parser.add_argument('-b-size', '--batch-size', default=256, type=int,\n",
    "                        metavar='N', help='mini-batch size (default: 256)')\n",
    "    parser.add_argument('--phases', default='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', type=str,\n",
    "                    help='Should be a string formatted like this: [(start_lr,end_lr,num_epochs),(phase2...)]')\n",
    "#     parser.add_argument('--init-bn0', action='store_true', help='Intialize running batch norm mean to 0')\n",
    "    parser.add_argument('--print-freq', '-p', default=200, type=int,\n",
    "                        metavar='N', help='print every this many steps (default: 5)')\n",
    "#     parser.add_argument('--no-bn-wd', action='store_true', help='Remove batch norm from weight decay')\n",
    "    parser.add_argument('--fp16', action='store_true', help='Run model fp16 mode.')\n",
    "    parser.add_argument('--loss-scale', type=float, default=1,\n",
    "                        help='Loss scaling, positive power of 2 values can improve fp16 convergence.')\n",
    "    parser.add_argument('--distributed', action='store_true', help='Run distributed training')\n",
    "    parser.add_argument('--world-size', default=-1, type=int, \n",
    "                        help='total number of processes (machines*gpus)')\n",
    "    parser.add_argument('--dist-url', default='env://', type=str,\n",
    "                        help='url used to set up distributed training')\n",
    "    parser.add_argument('--dist-backend', default='nccl', type=str, help='distributed backend')\n",
    "    parser.add_argument('--local_rank', default=0, type=int,\n",
    "                        help='Used for multi-process training. Can either be manually set ' +\n",
    "                        'or automatically set by using \\'python -m multiproc\\'.')\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, shutil, time, warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_input = [\n",
    "    '/home/paperspace/data/cifar10', \n",
    "    '--save-dir', '/home/paperspace/data/cifar_training/preact_test',\n",
    "    '-b', '256', \n",
    "    '--loss-scale', '512',\n",
    "    '--fp16',\n",
    "    '--wd', '5e-4',\n",
    "    '--momentum', '0.9',\n",
    "    '--phases', '[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]'\n",
    "#     '--train-half' # With fp16, iterations are so fast this doesn't matter\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "args = get_parser().parse_args(args_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.models.cifar10.wideresnet import wrn_22_cat, wrn_22, WideResNetConcat\n",
    "torch.backends.cudnn.benchmark = True\n",
    "PATH = Path.home()/'data/cifar10/'\n",
    "os.makedirs(PATH,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "def pad(img, p=4, padding_mode='reflect'):\n",
    "    return Image.fromarray(np.pad(np.asarray(img), ((p, p), (p, p), (0, 0)), padding_mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --\n",
    "# Model definition\n",
    "# Derived from models in `https://github.com/kuangliu/pytorch-cifar`\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bn1   = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        return out + shortcut\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_blocks=[2, 2, 2, 2], num_classes=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            self._make_layer(64, 64, num_blocks[0], stride=1),\n",
    "            self._make_layer(64, 128, num_blocks[1], stride=2),\n",
    "            self._make_layer(128, 256, num_blocks[2], stride=2),\n",
    "            self._make_layer(256, 256, num_blocks[3], stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, in_channels, out_channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(PreActBlock(in_channels=in_channels, out_channels=out_channels, stride=stride))\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.prep(x)\n",
    "        \n",
    "        x = self.layers(x)\n",
    "        \n",
    "        x_avg = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x_avg = x_avg.view(x_avg.size(0), -1)\n",
    "        \n",
    "        x_max = F.adaptive_max_pool2d(x, (1, 1))\n",
    "        x_max = x_max.view(x_max.size(0), -1)\n",
    "        \n",
    "        x = torch.cat([x_avg, x_max], dim=-1)\n",
    "        \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fast_collate(batch):\n",
    "    if not batch: return torch.tensor([]), torch.tensor([])\n",
    "    imgs = [img[0] for img in batch]\n",
    "    targets = torch.tensor([target[1] for target in batch], dtype=torch.int64)\n",
    "    w = imgs[0].size[0]\n",
    "    h = imgs[0].size[1]\n",
    "    tensor = torch.zeros( (len(imgs), 3, h, w), dtype=torch.uint8 )\n",
    "    for i, img in enumerate(imgs):\n",
    "        nump_array = np.asarray(img, dtype=np.uint8)\n",
    "        tens = torch.from_numpy(nump_array)\n",
    "        if(nump_array.ndim < 3):\n",
    "            nump_array = np.expand_dims(nump_array, axis=-1)\n",
    "        nump_array = np.rollaxis(nump_array, 2)\n",
    "        tensor[i] += torch.from_numpy(nump_array)\n",
    "\n",
    "        # Seems to be slower for our pipeline. Need to ask Sylvain\n",
    "        # tensor[i] += pil2tensor(img)\n",
    "        \n",
    "    return tensor, targets\n",
    "\n",
    "\n",
    "def torch_loader(data_path, size, bs, val_bs=None):\n",
    "\n",
    "    val_bs = val_bs or bs\n",
    "    # Data loading code\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=True, transform=train_tfms)\n",
    "    val_dataset  = datasets.CIFAR10(root=data_path, train=False, download=True)\n",
    "    \n",
    "    train_sampler = (torch.utils.data.distributed.DistributedSampler(train_dataset) if args.distributed else None)\n",
    "#     val_sampler = (torch.utils.data.distributed.DistributedSampler(val_dataset) if args.distributed else None)\n",
    "    val_sampler = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=(train_sampler is None),\n",
    "        num_workers=args.workers, pin_memory=True, sampler=train_sampler, collate_fn=fast_collate)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True, sampler=val_sampler, collate_fn=fast_collate)\n",
    "    \n",
    "#     if prefetcher:\n",
    "#     train_loader = DataPrefetcher(train_loader, fp16=True)\n",
    "#     val_loader = DataPrefetcher(val_loader, fp16=True)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class DataPrefetcher():\n",
    "    def __init__(self, loader, prefetch=True, fp16=False):\n",
    "        self.loader = loader\n",
    "        self.prefetch = prefetch\n",
    "        self.mean = torch.tensor([0.4914 * 255, 0.4822 * 255, 0.4465 * 255]).cuda().view(1,3,1,1)\n",
    "        self.std = torch.tensor([0.24703 * 255, 0.24349 * 255, 0.26159 * 255]).cuda().view(1,3,1,1)\n",
    "        self.fp16 = fp16\n",
    "        self.loaditer = iter(self.loader)\n",
    "        if self.fp16:\n",
    "            self.mean = self.mean.half()\n",
    "            self.std = self.std.half()\n",
    "        if self.prefetch:\n",
    "            self.stream = torch.cuda.Stream()\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            self.preload()\n",
    "\n",
    "    def __len__(self): return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        self.next_input, self.next_target = next(self.loaditer)\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.process_input(self.next_input)\n",
    "            self.next_target = self.next_target.cuda(non_blocking=True)\n",
    "    \n",
    "    def process_input(self, input, non_blocking=True):\n",
    "        input = input.cuda(non_blocking=non_blocking)\n",
    "        if self.fp16: input = input.half()\n",
    "        else: input = input.float()\n",
    "        if len(input.shape) < 3: return input\n",
    "        return input.sub_(self.mean).div_(self.std)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        if not self.prefetch:\n",
    "            for input, target in self.loaditer:\n",
    "                yield self.process_input(input), target.cuda()\n",
    "            return\n",
    "        while True:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            try: self.preload() # 0.5 fix\n",
    "            except Exception as e:\n",
    "                yield input, target\n",
    "                break\n",
    "            yield input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# orig submission params\n",
    "# bs = 128\n",
    "# lrs = (0, 1e-1, 5e-3, 0)\n",
    "\n",
    "# higher batch size - able to converge around epoch 31 ~ 3:48\n",
    "# bs = 256\n",
    "# lrs = (0, 2e-1, 1e-2, 0)\n",
    "\n",
    "# wd=5e-4\n",
    "# # lr=1e-1\n",
    "# momentum = 0.9\n",
    "\n",
    "sz = 32\n",
    "trn_loader, val_loader = torch_loader(PATH, sz, args.batch_size, args.batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval('[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lrs = (0, 2e-1, 1e-2, 0)\n",
    "# start_lr, end_lr, num_epochs\n",
    "# [(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]\n",
    "\n",
    "\n",
    "class Scheduler():\n",
    "    def __init__(self, optimizer, phases=[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]):\n",
    "        self.optimizer = optimizer\n",
    "        self.current_lr = None\n",
    "        self.phases = phases\n",
    "        self.tot_epochs = sum([p[2] for p in phases])\n",
    "\n",
    "    def linear_lr(self, start_lr, end_lr, epoch_curr, batch_curr, epoch_tot, batch_tot):\n",
    "        step_tot = epoch_tot * batch_tot\n",
    "        step_curr = epoch_curr * batch_tot + epoch_curr\n",
    "        step_size = (end_lr - start_lr)/step_tot\n",
    "        return start_lr + step_curr * step_size\n",
    "    \n",
    "    def get_current_phase(self, epoch):\n",
    "        epoch_accum = 0\n",
    "        for phase in self.phases:\n",
    "            start_lr,end_lr,num_epochs = phase\n",
    "            if epoch <= epoch_accum+num_epochs: return start_lr, end_lr, num_epochs, epoch - epoch_accum\n",
    "            epoch_accum += num_epochs\n",
    "        raise Exception('Epoch out of range')\n",
    "            \n",
    "    def get_lr(self, epoch, batch_curr, batch_tot):\n",
    "        start_lr, end_lr, num_epochs, relative_epoch = self.get_current_phase(epoch)\n",
    "        return self.linear_lr(start_lr, end_lr, relative_epoch, batch_curr, num_epochs, batch_tot)\n",
    "\n",
    "    def update_lr(self, epoch, batch_num, batch_tot):\n",
    "        lr = self.get_lr(epoch, batch_num, batch_tot)\n",
    "        if (self.current_lr != lr) and ((batch_num == 1) or (batch_num == batch_tot)): \n",
    "            print(f'Changing LR from {self.current_lr} to {lr}')\n",
    "\n",
    "        self.current_lr = lr\n",
    "\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            lr_old = param_group['lr'] or lr\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "            # Trick 4: apply momentum correction when lr is updated\n",
    "            # https://github.com/pytorch/examples/pull/262\n",
    "#             if lr > lr_old: param_group['momentum'] = lr / lr_old * args.momentum\n",
    "#             else: param_group['momentum'] = args.momentum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def str_to_num_array(argstr, num_type=int):\n",
    "    return [num_type(s) for s in argstr.split(',')]\n",
    "\n",
    "# item() is a recent addition, so this helps with backward compatibility.\n",
    "def to_python_float(t):\n",
    "    if hasattr(t, 'item'):\n",
    "        return t.item()\n",
    "    else:\n",
    "        return float(t[0])\n",
    "#         return t[0]\n",
    "\n",
    "def train(trn_loader, model, criterion, optimizer, scheduler, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    st = time.time()\n",
    "    trn_len = len(trn_loader)\n",
    "\n",
    "    # print('Begin training loop:', st)\n",
    "    for i,(input,target) in enumerate(DataPrefetcher(trn_loader)):\n",
    "        batch_size = input.size(0)\n",
    "        batch_num = i+1\n",
    "        # if i == 0: print('Received input:', time.time()-st)\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        scheduler.update_lr(epoch, i+1, trn_len)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        if args.distributed:\n",
    "            # Must keep track of global batch size, since not all machines are guaranteed equal batches at the end of an epoch\n",
    "            corr1 = correct(output.data, target)\n",
    "            metrics = torch.tensor([batch_size, loss, corr1]).float().cuda()\n",
    "            batch_total, reduced_loss, corr1 = sum_tensor(metrics)\n",
    "            reduced_loss = reduced_loss/dist.get_world_size()\n",
    "            prec1 = corr1*(100.0/batch_total)\n",
    "        else:\n",
    "            reduced_loss = loss.data\n",
    "            batch_total = input.size(0)\n",
    "            prec1 = accuracy(output.data, target) # measure accuracy and record loss\n",
    "\n",
    "        losses.update(to_python_float(reduced_loss), batch_total)\n",
    "        top1.update(to_python_float(prec1), batch_total)\n",
    "\n",
    "        loss = loss*args.loss_scale\n",
    "        # compute gradient and do SGD step\n",
    "        # if i == 0: print('Evaluate and loss:', time.time()-st)\n",
    "        if args.fp16:\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            model_grads_to_master_grads(model_params, master_params)\n",
    "            for param in master_params:\n",
    "                param.grad.data = param.grad.data/args.loss_scale\n",
    "            optimizer.step()\n",
    "            master_params_to_model_params(model_params, master_params)\n",
    "            torch.cuda.synchronize()\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # if i == 0: print('Backward step:', time.time()-st)\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==trn_len)\n",
    "        if args.local_rank == 0 and should_print:\n",
    "            output = ('Epoch: [{0}][{1}/{2}]\\t' \\\n",
    "                    + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                    + 'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t' \\\n",
    "                    + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                    + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})').format(\n",
    "                    epoch, batch_num, trn_len, batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1)\n",
    "            print(output)\n",
    "            with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "                f.write(output + '\\n')\n",
    "    \n",
    "def validate(val_loader, model, criterion, epoch, start_time):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.eval()\n",
    "    end = time.time()\n",
    "    val_len = len(val_loader)\n",
    "\n",
    "    for i,(input,target) in enumerate(DataPrefetcher(val_loader)):\n",
    "        batch_num = i+1\n",
    "        if args.distributed and False: # (AS) Remove this later\n",
    "            prec1, loss, batch_total = distributed_predict(input, target, model, criterion)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target).data\n",
    "            batch_total = input.size(0)\n",
    "            prec1 = accuracy(output.data, target)\n",
    "            \n",
    "        losses.update(to_python_float(loss), batch_total)\n",
    "        top1.update(to_python_float(prec1), batch_total)\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        should_print = (batch_num%args.print_freq == 0) or (batch_num==val_len)\n",
    "        if args.local_rank == 0 and should_print:\n",
    "#             output = (batch_num, val_len,batch_time,losses,top1)\n",
    "            output = ('Test: [{0}/{1}]\\t' \\\n",
    "                    + 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t' \\\n",
    "                    + 'Loss {loss.val:.4f} ({loss.avg:.4f})\\t' \\\n",
    "                    + 'Prec@1 {top1.val:.3f} ({top1.avg:.3f})').format(\n",
    "                    batch_num, val_len, batch_time=batch_time, loss=losses,\n",
    "                    top1=top1)\n",
    "            print(output)\n",
    "            with open(f'{args.save_dir}/full.log', 'a') as f:\n",
    "                f.write(output + '\\n')\n",
    "\n",
    "\n",
    "def distributed_predict(input, target, model, criterion):\n",
    "    batch_size = input.size(0)\n",
    "    output = loss = corr1 = valid_batches = 0\n",
    "    \n",
    "    if batch_size:\n",
    "        # compute output\n",
    "        with torch.no_grad():\n",
    "            # using module instead of model because DistributedDataParallel forward function has a sync point.\n",
    "            # with distributed validation sampler, we don't always have data for each gpu\n",
    "            assert(is_distributed_model(model))\n",
    "            output = model.module(input)\n",
    "            loss = criterion(output, target).data\n",
    "        # measure accuracy and record loss\n",
    "        valid_batches = 1\n",
    "        corr1 = correct(output.data, target)\n",
    "\n",
    "    metrics = torch.tensor([batch_size, valid_batches, loss, corr1]).float().cuda()\n",
    "    batch_total, valid_batches, reduced_loss, corr1 = sum_tensor(metrics)\n",
    "    reduced_loss = reduced_loss/valid_batches\n",
    "\n",
    "    prec1 = corr1*(100.0/batch_total)\n",
    "    return prec1, reduced_loss, batch_total\n",
    "\n",
    "def is_distributed_model(model):\n",
    "    return isinstance(model, nn.parallel.DistributedDataParallel)# or (args.c10d and isinstance(model, distributed_c10d._DistributedDataParallelC10d))\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = self.avg = self.sum = self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    corrrect_ks = correct(output, target, topk)\n",
    "    batch_size = target.size(0)\n",
    "    return [correct_k.float().mul_(100.0 / batch_size) for correct_k in corrrect_ks]\n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).sum(0, keepdim=True)\n",
    "        res.append(correct_k)\n",
    "    return res\n",
    "\n",
    "\n",
    "def sum_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    return rt\n",
    "\n",
    "def reduce_tensor(tensor):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.reduce_op.SUM)\n",
    "    rt /= args.world_size\n",
    "    return rt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=256, data='/home/paperspace/data/cifar10', dist_backend='nccl', dist_url='env://', distributed=False, fp16=True, local_rank=0, loss_scale=512.0, momentum=0.9, phases='[(0,2e-1,15),(2e-1,1e-2,15),(1e-2,0,5)]', print_freq=200, save_dir='/home/paperspace/data/cifar_training/preact_test', weight_decay=0.0005, workers=8, world_size=-1)\n",
      "~~epoch\thours\ttop1Accuracy\n",
      "\n",
      "Begin training\n",
      "Changing LR from None to 0.0\n",
      "Epoch: [0][196/196]\tTime 0.022 (0.036)\tData 0.001 (0.003)\tLoss 2.3730 (2.3325)\tPrec@1 7.500 (10.116)\n",
      "Test: [20/20]\tTime 0.011 (0.042)\tLoss 2.3555 (2.3343)\tPrec@1 11.397 (10.320)\n",
      "Changing LR from 0.0 to 0.013401360544217686\n",
      "Epoch: [1][196/196]\tTime 0.037 (0.037)\tData 0.001 (0.004)\tLoss 0.9814 (1.4291)\tPrec@1 66.250 (47.498)\n",
      "Test: [20/20]\tTime 0.045 (0.041)\tLoss 1.4111 (1.3104)\tPrec@1 46.691 (53.550)\n",
      "Changing LR from 0.013401360544217686 to 0.02680272108843537\n",
      "Epoch: [2][196/196]\tTime 0.022 (0.037)\tData 0.000 (0.004)\tLoss 0.7490 (0.9464)\tPrec@1 68.750 (66.256)\n",
      "Test: [20/20]\tTime 0.010 (0.040)\tLoss 1.1289 (1.0000)\tPrec@1 61.397 (66.270)\n",
      "Changing LR from 0.02680272108843537 to 0.04020408163265306\n",
      "Epoch: [3][196/196]\tTime 0.054 (0.037)\tData 0.001 (0.004)\tLoss 0.7251 (0.7370)\tPrec@1 72.500 (74.188)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.9980 (0.9039)\tPrec@1 65.074 (69.240)\n",
      "Changing LR from 0.04020408163265306 to 0.05360544217687074\n",
      "Epoch: [4][196/196]\tTime 0.032 (0.037)\tData 0.001 (0.004)\tLoss 0.7471 (0.6261)\tPrec@1 77.500 (78.190)\n",
      "Test: [20/20]\tTime 0.010 (0.042)\tLoss 0.9658 (1.0297)\tPrec@1 68.382 (66.700)\n",
      "Changing LR from 0.05360544217687074 to 0.06700680272108843\n",
      "Epoch: [5][196/196]\tTime 0.016 (0.037)\tData 0.001 (0.004)\tLoss 0.4382 (0.5624)\tPrec@1 85.000 (80.544)\n",
      "Test: [20/20]\tTime 0.010 (0.043)\tLoss 0.8418 (0.7831)\tPrec@1 70.588 (73.180)\n",
      "Changing LR from 0.06700680272108843 to 0.08040816326530612\n",
      "Epoch: [6][196/196]\tTime 0.031 (0.037)\tData 0.001 (0.004)\tLoss 0.4509 (0.5144)\tPrec@1 82.500 (82.306)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.7144 (0.6665)\tPrec@1 75.000 (77.290)\n",
      "Changing LR from 0.08040816326530612 to 0.0938095238095238\n",
      "Epoch: [7][196/196]\tTime 0.017 (0.036)\tData 0.002 (0.003)\tLoss 0.5400 (0.4672)\tPrec@1 80.000 (83.918)\n",
      "Test: [20/20]\tTime 0.053 (0.043)\tLoss 0.6758 (0.5765)\tPrec@1 79.412 (81.080)\n",
      "Changing LR from 0.0938095238095238 to 0.10721088435374149\n",
      "Epoch: [8][196/196]\tTime 0.035 (0.037)\tData 0.001 (0.004)\tLoss 0.3943 (0.4369)\tPrec@1 86.250 (84.806)\n",
      "Test: [20/20]\tTime 0.010 (0.039)\tLoss 0.6099 (0.5793)\tPrec@1 76.838 (81.100)\n",
      "Changing LR from 0.10721088435374149 to 0.12061224489795919\n",
      "Epoch: [9][196/196]\tTime 0.023 (0.037)\tData 0.001 (0.004)\tLoss 0.4712 (0.4168)\tPrec@1 87.500 (85.588)\n",
      "Test: [20/20]\tTime 0.011 (0.043)\tLoss 0.4941 (0.5453)\tPrec@1 82.721 (81.340)\n",
      "Changing LR from 0.12061224489795919 to 0.13401360544217686\n",
      "Epoch: [10][196/196]\tTime 0.036 (0.038)\tData 0.001 (0.005)\tLoss 0.5210 (0.4029)\tPrec@1 86.250 (86.006)\n",
      "Test: [20/20]\tTime 0.013 (0.040)\tLoss 0.5054 (0.5174)\tPrec@1 84.191 (82.290)\n",
      "Changing LR from 0.13401360544217686 to 0.14741496598639456\n",
      "Epoch: [11][196/196]\tTime 0.018 (0.036)\tData 0.001 (0.004)\tLoss 0.3779 (0.3923)\tPrec@1 86.250 (86.530)\n",
      "Test: [20/20]\tTime 0.010 (0.040)\tLoss 0.6113 (0.5497)\tPrec@1 76.838 (80.880)\n",
      "Changing LR from 0.14741496598639456 to 0.16081632653061223\n",
      "Epoch: [12][196/196]\tTime 0.021 (0.037)\tData 0.001 (0.004)\tLoss 0.4106 (0.3835)\tPrec@1 85.000 (86.714)\n",
      "Test: [20/20]\tTime 0.028 (0.042)\tLoss 1.1826 (1.0261)\tPrec@1 65.074 (71.360)\n",
      "Changing LR from 0.16081632653061223 to 0.17421768707482993\n",
      "Epoch: [13][196/196]\tTime 0.022 (0.036)\tData 0.001 (0.003)\tLoss 0.3926 (0.3931)\tPrec@1 85.000 (86.458)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.6465 (0.6241)\tPrec@1 74.632 (79.450)\n",
      "Changing LR from 0.17421768707482993 to 0.1876190476190476\n",
      "Epoch: [14][196/196]\tTime 0.036 (0.037)\tData 0.001 (0.004)\tLoss 0.4932 (0.3896)\tPrec@1 85.000 (86.512)\n",
      "Test: [20/20]\tTime 0.010 (0.040)\tLoss 0.8325 (0.7049)\tPrec@1 73.529 (77.290)\n",
      "Changing LR from 0.1876190476190476 to 0.2010204081632653\n",
      "Epoch: [15][196/196]\tTime 0.055 (0.038)\tData 0.001 (0.004)\tLoss 0.4778 (0.3921)\tPrec@1 85.000 (86.566)\n",
      "Test: [20/20]\tTime 0.013 (0.037)\tLoss 1.3721 (1.1676)\tPrec@1 68.015 (70.580)\n",
      "Changing LR from 0.2010204081632653 to 0.1872687074829932\n",
      "Epoch: [16][196/196]\tTime 0.017 (0.037)\tData 0.001 (0.005)\tLoss 0.3569 (0.3632)\tPrec@1 83.750 (87.658)\n",
      "Test: [20/20]\tTime 0.010 (0.043)\tLoss 0.7729 (0.7818)\tPrec@1 73.529 (74.930)\n",
      "Changing LR from 0.1872687074829932 to 0.1745374149659864\n",
      "Epoch: [17][196/196]\tTime 0.049 (0.037)\tData 0.001 (0.004)\tLoss 0.2654 (0.3430)\tPrec@1 90.000 (88.258)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.6372 (0.5391)\tPrec@1 78.676 (82.220)\n",
      "Changing LR from 0.1745374149659864 to 0.1618061224489796\n",
      "Epoch: [18][196/196]\tTime 0.043 (0.036)\tData 0.002 (0.004)\tLoss 0.1354 (0.3241)\tPrec@1 96.250 (88.800)\n",
      "Test: [20/20]\tTime 0.009 (0.039)\tLoss 0.5903 (0.6182)\tPrec@1 82.353 (80.430)\n",
      "Changing LR from 0.1618061224489796 to 0.1490748299319728\n",
      "Epoch: [19][196/196]\tTime 0.033 (0.037)\tData 0.001 (0.004)\tLoss 0.3062 (0.2984)\tPrec@1 90.000 (89.686)\n",
      "Test: [20/20]\tTime 0.010 (0.040)\tLoss 0.5044 (0.5430)\tPrec@1 83.456 (82.260)\n",
      "Changing LR from 0.1490748299319728 to 0.136343537414966\n",
      "Epoch: [20][196/196]\tTime 0.018 (0.037)\tData 0.001 (0.004)\tLoss 0.3274 (0.2799)\tPrec@1 87.500 (90.260)\n",
      "Test: [20/20]\tTime 0.014 (0.039)\tLoss 0.4587 (0.4482)\tPrec@1 84.191 (85.100)\n",
      "Changing LR from 0.136343537414966 to 0.12361224489795919\n",
      "Epoch: [21][196/196]\tTime 0.055 (0.037)\tData 0.001 (0.004)\tLoss 0.1893 (0.2606)\tPrec@1 93.750 (90.900)\n",
      "Test: [20/20]\tTime 0.011 (0.040)\tLoss 0.4229 (0.4807)\tPrec@1 85.294 (84.250)\n",
      "Changing LR from 0.12361224489795919 to 0.11088095238095239\n",
      "Epoch: [22][196/196]\tTime 0.019 (0.036)\tData 0.001 (0.003)\tLoss 0.1487 (0.2402)\tPrec@1 95.000 (91.604)\n",
      "Test: [20/20]\tTime 0.010 (0.039)\tLoss 0.4834 (0.5508)\tPrec@1 85.662 (82.840)\n",
      "Changing LR from 0.11088095238095239 to 0.09814965986394558\n",
      "Epoch: [23][196/196]\tTime 0.017 (0.037)\tData 0.001 (0.004)\tLoss 0.2152 (0.2184)\tPrec@1 91.250 (92.314)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.4480 (0.4589)\tPrec@1 84.559 (85.610)\n",
      "Changing LR from 0.09814965986394558 to 0.08541836734693878\n",
      "Epoch: [24][196/196]\tTime 0.023 (0.037)\tData 0.001 (0.005)\tLoss 0.1639 (0.2006)\tPrec@1 95.000 (93.116)\n",
      "Test: [20/20]\tTime 0.010 (0.040)\tLoss 0.3550 (0.3385)\tPrec@1 87.868 (88.720)\n",
      "Changing LR from 0.08541836734693878 to 0.07268707482993197\n",
      "Epoch: [25][196/196]\tTime 0.029 (0.037)\tData 0.001 (0.004)\tLoss 0.2375 (0.1763)\tPrec@1 92.500 (93.946)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.4585 (0.4005)\tPrec@1 86.397 (87.320)\n",
      "Changing LR from 0.07268707482993197 to 0.05995578231292517\n",
      "Epoch: [26][196/196]\tTime 0.016 (0.037)\tData 0.001 (0.004)\tLoss 0.1136 (0.1507)\tPrec@1 97.500 (94.806)\n",
      "Test: [20/20]\tTime 0.046 (0.040)\tLoss 0.2886 (0.2780)\tPrec@1 91.912 (90.600)\n",
      "Changing LR from 0.05995578231292517 to 0.04722448979591837\n",
      "Epoch: [27][196/196]\tTime 0.018 (0.037)\tData 0.001 (0.004)\tLoss 0.1234 (0.1232)\tPrec@1 95.000 (95.830)\n",
      "Test: [20/20]\tTime 0.012 (0.043)\tLoss 0.2585 (0.2915)\tPrec@1 91.176 (90.740)\n",
      "Changing LR from 0.04722448979591837 to 0.034493197278911564\n",
      "Epoch: [28][196/196]\tTime 0.025 (0.037)\tData 0.002 (0.004)\tLoss 0.2678 (0.0948)\tPrec@1 92.500 (96.762)\n",
      "Test: [20/20]\tTime 0.010 (0.039)\tLoss 0.2871 (0.2680)\tPrec@1 90.809 (91.700)\n",
      "Changing LR from 0.034493197278911564 to 0.02176190476190476\n",
      "Epoch: [29][196/196]\tTime 0.038 (0.037)\tData 0.004 (0.004)\tLoss 0.0959 (0.0705)\tPrec@1 96.250 (97.624)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.2686 (0.2353)\tPrec@1 92.647 (92.770)\n",
      "Changing LR from 0.02176190476190476 to 0.009030612244897956\n",
      "Epoch: [30][196/196]\tTime 0.030 (0.037)\tData 0.001 (0.003)\tLoss 0.0204 (0.0482)\tPrec@1 100.000 (98.442)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.2095 (0.2055)\tPrec@1 94.853 (93.680)\n",
      "Changing LR from 0.009030612244897956 to 0.007989795918367347\n",
      "Epoch: [31][196/196]\tTime 0.017 (0.037)\tData 0.001 (0.004)\tLoss 0.0253 (0.0386)\tPrec@1 100.000 (98.774)\n",
      "Test: [20/20]\tTime 0.057 (0.043)\tLoss 0.2064 (0.2041)\tPrec@1 94.853 (93.860)\n",
      "Changing LR from 0.007989795918367347 to 0.005979591836734694\n",
      "Epoch: [32][196/196]\tTime 0.061 (0.037)\tData 0.001 (0.004)\tLoss 0.0364 (0.0342)\tPrec@1 98.750 (98.996)\n",
      "Test: [20/20]\tTime 0.010 (0.040)\tLoss 0.2118 (0.2034)\tPrec@1 93.750 (93.810)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing LR from 0.005979591836734694 to 0.003969387755102041\n",
      "Epoch: [33][196/196]\tTime 0.058 (0.037)\tData 0.003 (0.004)\tLoss 0.0168 (0.0292)\tPrec@1 100.000 (99.136)\n",
      "Test: [20/20]\tTime 0.013 (0.038)\tLoss 0.1936 (0.2049)\tPrec@1 94.853 (93.820)\n",
      "Changing LR from 0.003969387755102041 to 0.0019591836734693877\n",
      "Epoch: [34][196/196]\tTime 0.032 (0.036)\tData 0.002 (0.003)\tLoss 0.0118 (0.0267)\tPrec@1 100.000 (99.236)\n",
      "Test: [20/20]\tTime 0.010 (0.041)\tLoss 0.1993 (0.2041)\tPrec@1 94.118 (93.940)\n"
     ]
    }
   ],
   "source": [
    "if args.distributed:\n",
    "    print('Distributed: initializing process group')\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url, world_size=args.world_size)\n",
    "    assert(args.world_size == dist.get_world_size())\n",
    "    print(\"Distributed: success (%d/%d)\"%(args.local_rank, args.world_size))\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help performance\n",
    "\n",
    "if args.fp16: model = network_to_half(model)\n",
    "elif args.distributed: model = nn.parallel.DistributedDataParallel(model, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "\n",
    "global model_params, master_params\n",
    "if args.fp16: model_params, master_params = prep_param_lists(model)\n",
    "else: master_params = list(model.parameters())\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion = F.cross_entropy\n",
    "optimizer = torch.optim.SGD(master_params, 0, nesterov=True, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "scheduler = Scheduler(optimizer, phases=eval(args.phases))\n",
    "\n",
    "\n",
    "print(args)\n",
    "print(\"~~epoch\\thours\\ttop1Accuracy\\n\")\n",
    "\n",
    "start_time = datetime.now() # Loading start to after everything is loaded\n",
    "print(\"Begin training\")\n",
    "for epoch in range(scheduler.tot_epochs):\n",
    "    train(trn_loader, model, criterion, optimizer, scheduler, epoch)\n",
    "    validate(val_loader, model, criterion, epoch, start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import Learner, TrainingPhase, ModelData, accuracy, DecayType\n",
    "from functools import partial\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def old_torch_loader(data_path, size, bs, val_bs=None, prefetcher=False):\n",
    "\n",
    "    val_bs = val_bs or bs\n",
    "    # Data loading code\n",
    "    tfms = [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.24703,0.24349,0.26159))]\n",
    "\n",
    "    train_tfms = transforms.Compose([\n",
    "        pad, # TODO: use `padding` rather than assuming 4\n",
    "        transforms.RandomCrop(size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "    ] + tfms)\n",
    "    val_tfms = transforms.Compose(tfms)\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=data_path, train=True, download=True, transform=train_tfms)\n",
    "    val_dataset  = datasets.CIFAR10(root=data_path, train=False, download=True, transform=val_tfms)\n",
    "    aug_dataset = datasets.CIFAR10(root=data_path, train=False, download=True, transform=train_tfms)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=bs, shuffle=True,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=val_bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "    \n",
    "    aug_loader = DataLoader(\n",
    "        aug_dataset,\n",
    "        batch_size=bs, shuffle=False,\n",
    "        num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "    if prefetcher:\n",
    "        train_loader = OldDataPrefetcher(train_loader)\n",
    "        val_loader = OldDataPrefetcher(val_loader)\n",
    "        aug_loader = OldDataPrefetcher(aug_loader)\n",
    "    \n",
    "    data = ModelData(data_path, train_loader, val_loader)\n",
    "    data.sz = size\n",
    "    data.aug_dl = aug_loader\n",
    "    return data\n",
    "\n",
    "# Seems to speed up training by ~2%\n",
    "class OldDataPrefetcher():\n",
    "    def __init__(self, loader, stop_after=None):\n",
    "        self.loader = loader\n",
    "        self.dataset = loader.dataset\n",
    "        self.stream = torch.cuda.Stream()\n",
    "        self.stop_after = stop_after\n",
    "        self.next_input = None\n",
    "        self.next_target = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.loader)\n",
    "\n",
    "    def preload(self):\n",
    "        try:\n",
    "            self.next_input, self.next_target = next(self.loaditer)\n",
    "        except StopIteration:\n",
    "            self.next_input = None\n",
    "            self.next_target = None\n",
    "            return\n",
    "        with torch.cuda.stream(self.stream):\n",
    "            self.next_input = self.next_input.cuda(async=True)\n",
    "            self.next_target = self.next_target.cuda(async=True)\n",
    "\n",
    "    def __iter__(self):\n",
    "        count = 0\n",
    "        self.loaditer = iter(self.loader)\n",
    "        self.preload()\n",
    "        while self.next_input is not None:\n",
    "            torch.cuda.current_stream().wait_stream(self.stream)\n",
    "            input = self.next_input\n",
    "            target = self.next_target\n",
    "            self.preload()\n",
    "            count += 1\n",
    "            yield input, target\n",
    "            if type(self.stop_after) is int and (count > self.stop_after):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.trn_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(data.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962ba244b5f745de8db8b0efb54f480e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.412447   2.159091   0.3951    \n",
      "    1      0.970583   1.630464   0.5208                      \n",
      "    2      0.749944   0.852949   0.7058                      \n",
      "    3      0.652545   1.217766   0.6298                      \n",
      "    4      0.556323   0.867725   0.7102                      \n",
      "    5      0.495791   0.74362    0.7525                      \n",
      "    6      0.46937    0.846975   0.7384                      \n",
      "    7      0.434401   0.677632   0.7743                      \n",
      "    8      0.417817   0.830285   0.7379                      \n",
      "    9      0.40224    0.617939   0.8005                      \n",
      "    10     0.392207   0.863409   0.732                       \n",
      "    11     0.39357    0.874344   0.7123                      \n",
      "    12     0.394713   0.571084   0.8028                      \n",
      "    13     0.384292   0.734388   0.7597                      \n",
      "    14     0.396824   0.559785   0.8139                      \n",
      "    15     0.372283   0.756653   0.7743                      \n",
      "    16     0.348567   0.557557   0.8149                      \n",
      "    17     0.335233   0.556744   0.8155                      \n",
      "    18     0.313058   0.482237   0.8397                      \n",
      "    19     0.290059   0.470443   0.8449                      \n",
      "    20     0.270218   0.534831   0.8292                      \n",
      "    21     0.254761   0.511711   0.8309                      \n",
      "    22     0.234975   0.399536   0.8661                      \n",
      "    23     0.210923   0.402545   0.8719                      \n",
      "    24     0.183734   0.285371   0.9061                      \n",
      "    25     0.171735   0.290125   0.9031                      \n",
      "    26     0.143216   0.26177    0.913                       \n",
      "    27     0.111375   0.244525   0.9196                      \n",
      "    28     0.083458   0.233215   0.9255                       \n",
      "    29     0.057431   0.205357   0.9372                       \n",
      "    30     0.040231   0.201416   0.9385                       \n",
      "    31     0.034351   0.204755   0.9393                       \n",
      "    32     0.029828   0.202863   0.9403                       \n",
      "    33     0.02738    0.201158   0.9417                       \n",
      "    34     0.02497    0.200434   0.9422                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.200433984375, 0.9422000000953674]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "if args.fp16: model = network_to_half(model)\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help performance\n",
    "\n",
    "wd=5e-4\n",
    "lr=1e-1\n",
    "momentum = 0.9\n",
    "# learn.clip = 1e-1\n",
    "bs = 256\n",
    "lrs = (0, 2e-1, 1e-2, 0)\n",
    "sz=32\n",
    "\n",
    "\n",
    "data = old_torch_loader(PATH, sz, bs, bs*2)\n",
    "    \n",
    "learn = Learner.from_model_data(model, data)\n",
    "# learn.half()\n",
    "learn.crit = F.cross_entropy\n",
    "learn.metrics = [accuracy]\n",
    "learn.opt_fn = partial(torch.optim.SGD, nesterov=True, momentum=0.9)\n",
    "def_phase = {'opt_fn':learn.opt_fn, 'wds':wd, 'momentum':0.9}\n",
    "\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=15, lr=lrs[:2], lr_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=15, lr=lrs[1:3], lr_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=5, lr=lrs[-2:], lr_decay=DecayType.LINEAR),\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638d24c7623a43eda43447006303a9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=35), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.455398   1.86548    36.12     \n",
      "    1      0.972145   2.053288   45.67                       \n",
      "    2      0.769381   0.941118   66.78                       \n",
      "    3      0.643727   1.122708   63.73                       \n",
      "    4      0.580281   0.987419   67.95                       \n",
      "    5      0.524518   0.812247   73.51                       \n",
      "    6      0.472833   1.092777   69.43                       \n",
      "    7      0.447318   0.613691   79.17                       \n",
      "    8      0.435333   1.137866   66.48                       \n",
      "    9      0.417069   1.191509   61.16                       \n",
      "    10     0.402149   1.107984   66.65                       \n",
      "    11     0.40548    0.664285   78.02                       \n",
      "    12     0.396633   1.074928   71.39                       \n",
      "    13     0.386369   0.764332   75.42                       \n",
      "    14     0.394707   0.966597   71.23                       \n",
      "    15     0.38009    1.273195   64.16                       \n",
      "    16     0.358265   0.530744   82.3                        \n",
      "    17     0.33489    2.065473   53.51                       \n",
      "    18     0.311555   0.670111   79.54                       \n",
      "    19     0.29223    0.44085    85.09                       \n",
      "    20     0.285386   0.613678   79.33                       \n",
      "    21     0.255805   0.44868    85.04                       \n",
      "    22     0.232596   0.47709    84.42                       \n",
      "    23     0.222712   0.435277   85.67                       \n",
      "    24     0.200925   0.418679   86.01                       \n",
      "    25     0.171387   0.345566   88.86                       \n",
      "    26     0.14288    0.283438   90.66                       \n",
      "    27     0.11212    0.254896   91.7                        \n",
      "    28     0.084731   0.243371   92.56                        \n",
      "    29     0.060838   0.227271   92.79                        \n",
      "    30     0.043069   0.21135    93.44                        \n",
      "    31     0.039104   0.21173    93.65                        \n",
      "    32     0.031308   0.207977   93.57                        \n",
      "    33     0.028036   0.208454   93.87                        \n",
      "    34     0.028603   0.209891   93.78                        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20989140625, array([93.78])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "\n",
    "# AS: todo: don't copy over weights as it seems to help performance\n",
    "\n",
    "wd=5e-4\n",
    "lr=1e-1\n",
    "momentum = 0.9\n",
    "# learn.clip = 1e-1\n",
    "bs = 256\n",
    "lrs = (0, 2e-1, 1e-2, 0)\n",
    "sz=32\n",
    "\n",
    "if args.fp16: model = network_to_half(model)\n",
    "\n",
    "trn_loader, val_loader = torch_loader(PATH, sz, bs, bs)\n",
    "data = ModelData(PATH, trn_loader, val_loader)\n",
    "\n",
    "learn = Learner.from_model_data(model, data)\n",
    "# learn.half()\n",
    "learn.crit = F.cross_entropy\n",
    "learn.metrics = [accuracy]\n",
    "learn.opt_fn = partial(torch.optim.SGD, nesterov=True, momentum=0.9)\n",
    "def_phase = {'opt_fn':learn.opt_fn, 'wds':wd, 'momentum':0.9}\n",
    "\n",
    "phases = [\n",
    "    TrainingPhase(**def_phase, epochs=15, lr=lrs[:2], lr_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=15, lr=lrs[1:3], lr_decay=DecayType.LINEAR),\n",
    "    TrainingPhase(**def_phase, epochs=5, lr=lrs[-2:], lr_decay=DecayType.LINEAR),\n",
    "]\n",
    "\n",
    "learn.fit_opt_sched(phases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
